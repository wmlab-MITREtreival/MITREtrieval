{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from query_list import *\n",
    "import sys\n",
    "import codecs\n",
    "#sys.stdout = codecs.getwriter(\"utf-8\")(sys.stdout.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  label\n",
      "0     Since early 2014, an attacker group of Iranian...      1\n",
      "1     pivoting for lateral movement and further malw...      1\n",
      "2     them interchangeably, as alternate infection m...      1\n",
      "3     vulnerabilities in common web platforms. • WSO...      1\n",
      "4     after successful compromise to allow further a...      1\n",
      "...                                                 ...    ...\n",
      "9295  \\Users\\USERNAME\\AppData\\Roaming\\Microsoft\\Wind...      1\n",
      "9296  1 [CONFIG] 2 name = %TEMP%\\sysh32.bat 3 exe = ...      1\n",
      "9297  1. store the payload in the ﬁle %TEMP%\\sysh32....      1\n",
      "9298  In 2011, we observed an evolved version of the...      1\n",
      "9299   -c, --commands_only Only output chopper commands      1\n",
      "\n",
      "[9300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "greeter = Ontology(\"bolt://140.115.54.74:7687\", \"neo4j\", \"wmlab\")\n",
    "\n",
    "group = greeter.query_all_group_name()\n",
    "software=greeter.query_all_software_name()\n",
    "with open(\"Data/Technique_name.txt\",\"rb\") as f:\n",
    "    Technique_name=pickle.load(f)\n",
    "f.close()\n",
    "Technique_name=[t.lower() for t in Technique_name]\n",
    "procedure=greeter.get_procdure(Technique_name)\n",
    "procedure=[re.sub(\"\\[\",\"\",pre) for pre in procedure]\n",
    "procedure=[re.sub(\"\\]\",\"\",pre) for pre in procedure]\n",
    "\n",
    "for i,procedure_iter in enumerate(procedure):\n",
    "    for group_iter in group:\n",
    "        if group_iter[0] in procedure_iter:\n",
    "            procedure[i]=procedure[i].replace(group_iter[0],'it')\n",
    "    for soft_iter in software:\n",
    "        if soft_iter[0] in procedure_iter:\n",
    "            procedure[i]=procedure[i].replace(soft_iter[0],'it')\n",
    "    print(procedure[i])\n",
    "\n",
    "true=[1]*len(procedure)\n",
    "df_true=pd.DataFrame({'Text':procedure,'label':true})\n",
    "print(df_true)\n",
    "'''\n",
    "with open(\"cycarrier_data\",\"rb\") as f:\n",
    "    positive=pickle.load(f)\n",
    "f.close()\n",
    "positive=positive[:9300]\n",
    "true=[1]*len(positive)\n",
    "positive['label']=true\n",
    "print(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1331\n"
     ]
    }
   ],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from nltk import sent_tokenize\n",
    "import urllib.request\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/03/12/europe/ukraine-invasion-friends-family-separated-cmd-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences=[]\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/travel/article/mexico-travel-covid-19/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/03/07/middleeast/bahrain-solar-diversifying-economy-spc-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/02/16/china/hong-kong-covid-singapore-mic-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/03/03/economy/china-cant-help-russia-sanctions-fallout-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/03/02/tech/russian-oneweb-launch-refusal/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/03/09/business/volkswagen-id-buzz/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/technology-60669538\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/world-australia-60686223\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/technology-60697261\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/uk-60679658\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.programiz.com/c-programming/examples/print-integer\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/business-60571395\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.programiz.com/python-programming/modules\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://docs.oracle.com/javaee/5/tutorial/doc/bnbis.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/60684682\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/science-environment-60662541\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.w3schools.com/sql/sql_examples.asp\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/business-60699815\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/business-60660760\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/business-60415367\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/business-60316224\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/av/world-asia-60689267\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "print(len(sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840\n"
     ]
    }
   ],
   "source": [
    "html = urllib.request.urlopen(\"https://www.bbc.com/future/bespoke/follow-the-food/the-foods-that-could-prevent-climate-disasters/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.bbc.com/news/technology-60709209\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.taiwannews.com.tw/en/news/4470690\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.taiwannews.com.tw/en/news/4469814\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://stackoverflow.com/questions/58868430/numpy-ndarray-object-has-no-attribute-values-using-reshape\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://philosophy.stackexchange.com/questions/89973/how-to-know-if-your-judgment-is-unbiased\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://stackoverflow.com/questions/71447916/create-a-2d-array-that-has-different-size-of-columns-using-java-scanner\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.cnbc.com/2022/03/11/didi-44percent-stock-plunge-leaves-softbank-and-uber-with-weak-returns.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "html = urllib.request.urlopen(\"https://www.cnbc.com/2022/03/12/russia-ukraine-live-updates.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "print(len(sentences))\n",
    "\n",
    "html = urllib.request.urlopen(\"https://www.reddit.com/r/learnprogramming/comments/tbqcnb/getting_to_a_point_where_im_not_relying_on/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "\n",
    "html = urllib.request.urlopen(\"https://www.reddit.com/r/learnprogramming/comments/tc2wt4/more_fun_than_i_thought_landed_a_volunteer_web/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.reddit.com/r/cybersecurity/comments/tbutsi/cissp_increasing_test_length/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.reddit.com/r/learnprogramming/comments/tbun3f/on_the_433th_day_of_my_journey_as_a_selftaught/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.reddit.com/r/learnprogramming/comments/tbtiwh/had_my_first_technical_interview_today/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://focustaiwan.tw/society/202203080027\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.reddit.com/r/learnprogramming/comments/tca1ag/how_to_get_a_job_at_a_gaming_company/\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "\n",
    "print(len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3241\n"
     ]
    }
   ],
   "source": [
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/politics/jan-6-hearing-takeaways-thursday/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/10/asia/shangri-la-dialogue-china-targeting-us-allies-intl-hnk-mic-ml/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/10/asia/india-nupur-sharma-islam-comments-explainer-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/business/gun-control-ceos-companies/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/business-food/sriracha-shortage/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/08/media/jurassic-park-box-office/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/tech/tiktok-time-spent/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/tech/ftc-lina-khan-tech/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/media/felicia-sonmez-washington-post/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/tech/tech-downturn/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/05/27/tech/elon-musk-twitter-sec/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/08/tech/lunar-robot-demonstration-jaxa-gitai-scn/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/07/tech/tech-giants-biden-adult-immigration/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/02/tech/depp-heard-verdict-metoo/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://www.yahoo.com/gma/police-responding-uvalde-shooting-may-222000408.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3936\n"
     ]
    }
   ],
   "source": [
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/10/europe/russia-putin-empire-restoration-endgame-intl-cmd/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/asia/thailand-cannabis-legal-minister-interview-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/10/asia/us-defense-secretary-austin-speech-intl-hnk-ml/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://news.yahoo.com/monarch-butterfly-populations-may-more-203200723.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://smartliferules.com/lp/quadair/2/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://news.yahoo.com/microplastics-found-fresh-antarctic-snow-230654105.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://news.yahoo.com/lifestyle/future-georgia-peaches-uncertain-due-212100240.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://news.yahoo.com/houston-bar-ranked-one-top-031800371.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://news.yahoo.com/russian-held-ukraine-region-scheming-213746215.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/09/media/felicia-sonmez-washington-post/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/10/europe/russia-putin-empire-restoration-endgame-intl-cmd/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/11/asia/north-korea-choe-son-hui-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/08/africa/gallery/hi-tech-automotive-superformance-cars-spc-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/08/middleeast/israel-palestinians-un-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://news.yahoo.com/russian-held-ukraine-region-scheming-213746215.htmll\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "print(len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9368\n"
     ]
    }
   ],
   "source": [
    "html = urllib.request.urlopen(\"https://edition.cnn.com/europe/live-news/russia-ukraine-war-news-06-20-22/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/style/article/skin-whitening-products-social-media-as-equals-intl-cmd/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/20/politics/biden-inflation-recession-gas-prices-analysis/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/20/asia/philippines-sara-duterte-sworn-in-vp-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/17/middleeast/shireen-abu-akleh-funeral-israeli-police-investigation-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/17/africa/funeral-nigeria-church-victims-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/17/americas/gustavo-petro-profile-intl-latam/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/10/politics/alejandro-mayorkas-interview-cnntv/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/19/china/china-anti-ballistic-missile-test-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/16/tennis/nick-kyrgios-australia-umpire-argument-spt-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/travel/article/africa-black-mountain-climbers-diversity-spc-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2021/02/02/sport/slovenia-chimney-climbing-europe-spt-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/05/06/middleeast/west-bank-land-legal-defeat-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/13/middleeast/iraq-sadr-parliament-resignation-mime-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/18/asia/intestinal-sickness-covid-north-korea-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/19/asia/monsoon-flooding-bangladesh-india-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/06/03/middleeast/turkey-name-change-mime-intl/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "html = urllib.request.urlopen(\"https://edition.cnn.com/2022/05/06/china/china-xi-pbsc-zero-covid-intl-hnk/index.html\").read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "texts=soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, texts)  \n",
    "all_text= u\" \".join(t.strip() for t in visible_texts)\n",
    "sentences.extend(sent_tokenize(all_text.strip()))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  label\n",
      "0     World Africa Americas Asia Australia More Chin...      0\n",
      "1     For loved ones ripped apart by war in Ukraine,...      0\n",
      "2     The 54-year-old carer, who managed to evacuate...      0\n",
      "3     Marina, who did not give her surname, was stil...      0\n",
      "4     \"And now I am all alone,\" Marina told CNN from...      0\n",
      "...                                                 ...    ...\n",
      "9363  Search Audio World Africa Americas Asia Austra...      0\n",
      "9364                                     A Warner Bros.      0\n",
      "9365                                 Discovery Company.      0\n",
      "9366                               All Rights Reserved.      0\n",
      "9367            CNN Sans ™ & © 2016 Cable News Network.      0\n",
      "\n",
      "[9368 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "false=[0]*len(sentences)\n",
    "df_false=pd.DataFrame({'Text':sentences,'label':false})\n",
    "print(df_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.concat([positive,df_false],axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text  label\n",
      "0    MoonBounce is notable for being the third publ...      1\n",
      "1    The source of the infection starts with a set ...      1\n",
      "2    Those hooks are used to divert the flow of the...      1\n",
      "3    This driver, which runs during the initial pha...      1\n",
      "4    Finally, the user mode malware reaches out to ...      1\n",
      "..                                                 ...    ...\n",
      "327  Once established within a system or network, a...      1\n",
      "328  Adversaries may use scripts automatically exec...      1\n",
      "329  Adversaries may use these scripts to maintain ...      1\n",
      "330  Adversaries may try to get information about r...      1\n",
      "331  Adversaries may look for folders and drives sh...      1\n",
      "\n",
      "[332 rows x 2 columns]\n",
      "                                                    Text  label\n",
      "0      Since early 2014, an attacker group of Iranian...      1\n",
      "1      pivoting for lateral movement and further malw...      1\n",
      "2      them interchangeably, as alternate infection m...      1\n",
      "3      vulnerabilities in common web platforms. • WSO...      1\n",
      "4      after successful compromise to allow further a...      1\n",
      "...                                                  ...    ...\n",
      "18995  Once established within a system or network, a...      1\n",
      "18996  Adversaries may use scripts automatically exec...      1\n",
      "18997  Adversaries may use these scripts to maintain ...      1\n",
      "18998  Adversaries may try to get information about r...      1\n",
      "18999  Adversaries may look for folders and drives sh...      1\n",
      "\n",
      "[19000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ans=pd.read_csv(\"Data/BERT_binary.csv\")\n",
    "print(ans)\n",
    "df=df.append(ans,ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Text  label\n",
      "0      Since early 2014, an attacker group of Iranian...      1\n",
      "1      pivoting for lateral movement and further malw...      1\n",
      "2      them interchangeably, as alternate infection m...      1\n",
      "3      vulnerabilities in common web platforms. • WSO...      1\n",
      "4      after successful compromise to allow further a...      1\n",
      "...                                                  ...    ...\n",
      "18995  Once established within a system or network, a...      1\n",
      "18996  Adversaries may use scripts automatically exec...      1\n",
      "18997  Adversaries may use these scripts to maintain ...      1\n",
      "18998  Adversaries may try to get information about r...      1\n",
      "18999  Adversaries may look for folders and drives sh...      1\n",
      "\n",
      "[19000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "with open('binary_bert_cy','wb') as f:\n",
    "    pickle.dump(df,f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4ebb9a2a12ede4fd53ba543d8939e3921ad9eb66d76bfa88e6cfe1ef6a1a299"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env_paper': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
